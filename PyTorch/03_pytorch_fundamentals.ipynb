{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#import torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "#import plot funcs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting Dataset\n",
    "\n",
    "we're gonna use the FashionMNIST dataset and import it using the built in datasets from torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Checking Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see first training example\n",
    "img, label = train_data[0]\n",
    "img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = train_data.class_to_idx\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check image shape\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img classication\n",
    "label, class_names[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img, label = train_data[0]\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "plt.imshow(img.squeeze())\n",
    "img.squeeze().shape, img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img.squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot more images\n",
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "\n",
    "rows, cols = 5,5\n",
    "for  i in range(1, rows * cols+1):\n",
    "    random_idx = torch.randint(0, len(train_data), size = [1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(class_names[label])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare DataLoader\n",
    "\n",
    "right now our data is in the form of PyTorch Datasets\n",
    "\n",
    "dataloader turns ut dataset into a python iterable\n",
    "\n",
    "more specifically, we cant to turn out data into batches (or mini-batches)\n",
    "\n",
    "we do this because:\n",
    "\n",
    "1. it is more computationally efficient to break our dataset into smaller batches\n",
    "2. it gives our NN more changes to update its gradients per epoch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#setup batch size hyperparameter\n",
    "BATCH_SIZE = 32 \n",
    "\n",
    "#turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(dataset=train_data, \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data, \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              shuffle=False)\n",
    "train_dataloader,test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check out what we've created\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\")\n",
    "print(f\"Length of train_dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of train_dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkout whats inside the training dataloader\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show a sample\n",
    "torch.manual_seed(42)\n",
    "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(class_names[label])\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"Label: {label}, label size: {label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model 0: Building a Baseline Model\n",
    "\n",
    "when making ML models, it's best practice to make a baseline model\n",
    "\n",
    "a baseline model is a simple model that we'll try to improve upon with subsequent models\n",
    "\n",
    "we start simple and add complexity when necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a flatten layer\n",
    "flatten_model = nn.Flatten()\n",
    "\n",
    "#get a single sample\n",
    "x = train_features_batch[0]\n",
    "\n",
    "#flatten sample\n",
    "output = flatten_model(x)\n",
    "\n",
    "print(f\"OG Shape: {x.shape}\")\n",
    "print(f\"Shape after flattening: {output.shape}\")\n",
    "x, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class fasionMNISTModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape = int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create instance\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model0 = fasionMNISTModel(input_shape=784, #pixels in 28 x 28 img \n",
    "                          hidden_units=8, #units in hidden layer\n",
    "                          output_shape=len(class_names)) #output probabilities for every class\n",
    "\n",
    "model0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = torch.rand([1,1,28,28])\n",
    "model0(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Setup Loss, Optimizer, and Evaluation Metrics\n",
    "\n",
    "* Loss Func - since we're workign with multi-class data, our loss function will be `nn.CrossEntropyLoss()`\n",
    "* Optimizer - `torch.optim.SGD()`\n",
    "* Eval Metric - since we're using classification, we'll use accuracy as our optimization metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "\n",
    "#set up loss func and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=model0.parameters(),\n",
    "                            lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to time how long our model takes\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def print_train_time(start:float, \n",
    "                     end:float, \n",
    "                     device: torch.device = None):\n",
    "    \"\"\"\n",
    "    prints difference between start and end time\n",
    "    \"\"\"\n",
    "    total_time = end-start\n",
    "    print(f\"Train time on: {device}: {total_time} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Creating a Training Loop on Batches of Data\n",
    "\n",
    "1. Loop through Epochs\n",
    "2. Loop through training batches, perform training steps, calculate the train loss per batch\n",
    "3. Loop through the testing batches, perform testing steps, calculate the test loss per batch\n",
    "4. Print out what's happening\n",
    "5. Time our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tgdm progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#set seed and start timer\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "train_time_start_cpu = timer()\n",
    "\n",
    "#set number of epochs (we'll keep this small for training time)\n",
    "epochs = 5\n",
    "\n",
    "#create training and test loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n\")\n",
    "\n",
    "    #Training\n",
    "    train_loss = 0\n",
    "    #add loop to loop through training batches\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model0.train()\n",
    "\n",
    "        #1. forward step\n",
    "        train_pred = model0(X)\n",
    "\n",
    "        #2. calc loss\n",
    "        loss = loss_fn(train_pred, y)\n",
    "        train_loss += loss\n",
    "        \n",
    "        #3. optim zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #4. back prop\n",
    "        loss.backward()\n",
    "\n",
    "        #5. optim step\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch % 100) == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples.\")        \n",
    "\n",
    "    #divide total train loss by length of train dataloader\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    ###Testing\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    model0.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dataloader:\n",
    "            #1. forward pass\n",
    "            test_pred = model0(X_test)\n",
    "\n",
    "            #2. calculate loss\n",
    "            test_loss += loss_fn(test_pred, y_test)\n",
    "\n",
    "            #3. calculate accuracy\n",
    "            test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
    "\n",
    "        test_loss /= len(test_data)\n",
    "        test_loss /= len(test_dataloader)\n",
    "    #print out whats happenign\n",
    "    print(f\"\\nTrain Loss: {train_loss} | Test Loss: {test_loss}, Test Acc = {test_acc}\")\n",
    "\n",
    "train_time_end_cpu = timer()\n",
    "\n",
    "total_train_time_mod_0 = print_train_time(start = train_time_start_cpu,\n",
    "                                          end = train_time_end_cpu,\n",
    "                                          device=str(next(model0.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Make Predictions for Model0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn):\n",
    "    \n",
    "    \"returns a dict containing the results of the model predicting on data_loader\"\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            #make pred\n",
    "            y_pred = model(X)\n",
    "\n",
    "            #loss and acc\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, \n",
    "                               y_pred=y_pred.argmax(dim=1))\n",
    "            \n",
    "        #scale loss and acc to find average values\n",
    "        loss /= len(data_loader)\n",
    "\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "    return {\"model name: \": model.__class__.__name__,\n",
    "            \"model loss: \": loss.item(),\n",
    "            \"model acc: \": acc}\n",
    "\n",
    "#calc model 0 results on test dataset\n",
    "model0_results = eval_model(model=model0,\n",
    "           data_loader=test_dataloader,\n",
    "           loss_fn=loss_fn,\n",
    "           accuracy_fn=accuracy_fn)\n",
    "\n",
    "model0_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Setup Device Agnostic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better Model with Non-Linearity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class fasionMNISTModel2(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape = int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "    \n",
    "model1 = fasionMNISTModel2(input_shape=28*28,\n",
    "                           hidden_units=8,\n",
    "                           output_shape=len(class_names)\n",
    "                           ).to(device)\n",
    "\n",
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model1.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "\n",
    "#set up loss func and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=model0.parameters(),\n",
    "                            lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop function\n",
    "\n",
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer, \n",
    "               accuracy_fn, \n",
    "               device: torch.device = device):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.train()\n",
    "\n",
    "    #add loop to loop through training batches\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        #put data on target device\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        #1. forward step\n",
    "        train_pred = model(X)\n",
    "\n",
    "        #2. calc loss\n",
    "        loss = loss_fn(train_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y, \n",
    "                                 y_pred=train_pred.argmax(dim=1)\n",
    "                                 )\n",
    "        \n",
    "        #3. optim zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #4. back prop\n",
    "        loss.backward()\n",
    "\n",
    "        #5. optim step\n",
    "        optimizer.step()                    \n",
    "\n",
    "    #divide total train loss and accuracy by length of train dataloader\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc  /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss} | Train Acc: {train_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing loop function\n",
    "def test_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer, \n",
    "               accuracy_fn, \n",
    "               device: torch.device = device):\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        #add loop to loop through training batches\n",
    "        for batch, (X, y) in enumerate(data_loader):\n",
    "            #put data on target device\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            #1. forward step\n",
    "            test_pred = model(X)\n",
    "\n",
    "            #2. calc loss\n",
    "            loss = loss_fn(test_pred, y)\n",
    "            test_loss += loss\n",
    "            test_acc += accuracy_fn(y_true=y, \n",
    "                                    y_pred=test_pred.argmax(dim=1)\n",
    "                                    )               \n",
    "\n",
    "    #divide total train loss and accuracy by length of train dataloader\n",
    "    test_loss = test_loss /len(data_loader)\n",
    "    test_acc  = test_acc/len(data_loader)\n",
    "    print(f\"Train loss: {test_loss} | Train Acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "train_step(model=model1,\n",
    "           data_loader=train_dataloader, \n",
    "           loss_fn=loss_fn,\n",
    "           optimizer=optimizer,\n",
    "           accuracy_fn=accuracy_fn,\n",
    "           device=device)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = test_step(model=model1,\n",
    "           data_loader=test_dataloader, \n",
    "           loss_fn=loss_fn,\n",
    "           optimizer=optimizer,\n",
    "           accuracy_fn=accuracy_fn,\n",
    "           device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with non-linear and linear layers\n",
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), # flatten inputs into single vector\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layer_stack(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_1 = FashionMNISTModelV1(input_shape=784, # number of input features\n",
    "    hidden_units=10,\n",
    "    output_shape=len(class_names) # number of output classes desired\n",
    ").to(device) # send model to GPU if it's available\n",
    "next(model_1.parameters()).device # check model device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(), \n",
    "                            lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device)\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # Send data to GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1)) # Go from logits -> pred labels\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "def test_step(data_loader: torch.utils.data.DataLoader,\n",
    "              model: torch.nn.Module,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.to(device)\n",
    "    model.eval() # put model in eval mode\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode(): \n",
    "        for X, y in data_loader:\n",
    "            # Send data to GPU\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "            \n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                y_pred=test_pred.argmax(dim=1) # Go from logits -> pred labels\n",
    "            )\n",
    "        \n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "epochs = 5\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=train_dataloader, \n",
    "        model=model_1, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn\n",
    "    )\n",
    "    test_step(data_loader=test_dataloader,\n",
    "        model=model_1,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn\n",
    "    )\n",
    "\n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu,\n",
    "                                            end=train_time_end_on_gpu,\n",
    "                                            device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move values to device\n",
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module, \n",
    "               data_loader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               accuracy_fn, \n",
    "               device: torch.device = device):\n",
    "    \"\"\"Evaluates a given model on a given dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
    "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
    "        loss_fn (torch.nn.Module): The loss function of model.\n",
    "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
    "        device (str, optional): Target device to compute on. Defaults to device.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Results of model making predictions on data_loader.\n",
    "    \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            # Send data to the target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "        \n",
    "        # Scale loss and acc\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "\n",
    "# Calculate model 1 results with device-agnostic code \n",
    "model_1_results = eval_model(model=model_1, data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn, accuracy_fn=accuracy_fn,\n",
    "    device=device\n",
    ")\n",
    "model_1_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Build a CNN \n",
    "\n",
    "CNNs are also known as ConvNets, they're used to find patterns in visual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a CNN\n",
    "class FashionMNISTV2(nn.Module):\n",
    "    def __init__(self, input_shape:int,\n",
    "                 hidden_units:int,\n",
    "                 output_shape:int):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            #create a conv later\n",
    "            nn.Conv2d(in_channels=input_shape, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1), #values we can set outselves in our NN are called hyperparameters\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels = hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3, \n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3, \n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=int(hidden_units * 49/8),\n",
    "                      out_features=output_shape,\n",
    "                      )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block_1(x)\n",
    "        print(f\"conv block 1 output shape: {x.shape}\")\n",
    "        x = self.conv_block_2(x)\n",
    "        print(f\"output shape of blkc 2: {x.shape}\")\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model2 = FashionMNISTV2(input_shape=1,\n",
    "                        hidden_units=8,\n",
    "                        output_shape=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Stepping Through NN.Conv2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "#create a batch of images\n",
    "images = torch.randn(size=(32, 3, 64,64))\n",
    "test_image = images[0]\n",
    "\n",
    "print(f\"Image batch shape: {images.shape}\")\n",
    "print(f\"Single image shape: {test_image.shape}\")\n",
    "print(f\"Test Image:\\n {test_image}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a single conv layer\n",
    "conv_layer = nn.Conv2d(in_channels=3,\n",
    "                       out_channels=8,\n",
    "                       kernel_size=(3,3), #kernel = filter, size of the filer that we're passing over our image for convolution\n",
    "                       stride=1,\n",
    "                       padding=0)\n",
    "\n",
    "#pass the data through the conv layer\n",
    "conv_output = conv_layer(test_image)\n",
    "conv_output, conv_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Steeping Through nn.MaxPool2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print original image shape without unsqueezed dimension\n",
    "print(f\"Test image og shape: {test_image.shape}\")\n",
    "print(f\"Test image with unsqueezed dimension: {test_image.unsqueeze(0).shape}\")\n",
    "\n",
    "#create a sample nn.MaxPool() layer\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "#pass data through just the conv layer\n",
    "test_img_through_conv = conv_layer(test_image.unsqueeze(dim=0))\n",
    "print(f\"Test image through conv_layer(): {test_img_through_conv.shape}\")\n",
    "\n",
    "#pass data through maxpool layer\n",
    "test_image_through_conv_and_max_pool = max_pool_layer(test_img_through_conv)\n",
    "print(f\"Shape after going through both: {test_image_through_conv_and_max_pool.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "#create a random tensor with a similar number of dimensions\n",
    "random_tensor = torch.randn(size=(1,1,2,2))\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a max pool layer\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "#pass rand tensor through max pool\n",
    "max_pool_tensor = max_pool_layer(random_tensor)\n",
    "print(f\"\\nMax pool tensor: \\n{max_pool_tensor}\")\n",
    "print(f\"\\nMax pool tensor shape: {max_pool_tensor.shape}\")\n",
    "\n",
    "print(f\"\\nrandom tensor: {random_tensor.shape}\")\n",
    "print(f\"\\ngrandom tensor shape: {random_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img.squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_image_tensor = torch.randn(size=(1,28,28))\n",
    "rand_image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2(rand_image_tensor.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Setup Loss Function and Optimizer for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params= model2.parameters(),\n",
    "                            lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Training and Testing Model 2 Using Training and Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "#train and test model\n",
    "epochs = 3\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    train_step(model=model2, \n",
    "               data_loader=train_dataloader,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               accuracy_fn=accuracy_fn,\n",
    "               device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a convolutional neural network \n",
    "class FashionMNISTModelV2(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture copying TinyVGG from: \n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3, # how big is the square that's going over the image?\n",
    "                      stride=1, # default\n",
    "                      padding=1),# options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2) # default stride value is same as kernel_size\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # Where did this in_features shape come from? \n",
    "            # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
    "            nn.Linear(in_features=hidden_units*7*7, \n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.block_1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.block_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_2 = FashionMNISTModelV2(input_shape=1, \n",
    "    hidden_units=10, \n",
    "    output_shape=len(class_names)).to(device)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Create sample batch of random numbers with same size as image batch\n",
    "images = torch.randn(size=(32, 3, 64, 64)) # [batch_size, color_channels, height, width]\n",
    "test_image = images[0] # get a single image for testing\n",
    "print(f\"Image batch shape: {images.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"Single image shape: {test_image.shape} -> [color_channels, height, width]\") \n",
    "print(f\"Single image pixel values:\\n{test_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a convolutional layer with same dimensions as TinyVGG \n",
    "# (try changing any of the parameters and see what happens)\n",
    "conv_layer = nn.Conv2d(in_channels=3,\n",
    "                       out_channels=10,\n",
    "                       kernel_size=3,\n",
    "                       stride=1,\n",
    "                       padding=0) # also try using \"valid\" or \"same\" here \n",
    "\n",
    "# Pass the data through the convolutional layer\n",
    "conv_layer(test_image) # Note: If running PyTorch <1.11.0, this will error because of shape issues (nn.Conv.2d() expects a 4d tensor as input) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "# Create a new conv_layer with different values (try setting these to whatever you like)\n",
    "conv_layer_2 = nn.Conv2d(in_channels=3, # same number of color channels as our input image\n",
    "                         out_channels=10,\n",
    "                         kernel_size=(5, 5), # kernel is usually a square so a tuple also works\n",
    "                         stride=2,\n",
    "                         padding=0)\n",
    "\n",
    "# Pass single image through new conv_layer_2 (this calls nn.Conv2d()'s forward() method on the input)\n",
    "conv_layer_2(test_image.unsqueeze(dim=0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the conv_layer_2 internal parameters\n",
    "print(conv_layer_2.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_model_2 = timer()\n",
    "\n",
    "# Train and test model \n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=train_dataloader, \n",
    "        model=model_2, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "    test_step(data_loader=test_dataloader,\n",
    "        model=model_2,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "train_time_end_model_2 = timer()\n",
    "total_train_time_model_2 = print_train_time(start=train_time_start_model_2,\n",
    "                                           end=train_time_end_model_2,\n",
    "                                           device=device)\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model_2 results \n",
    "model_2_results = eval_model(\n",
    "    model=model_2,\n",
    "    data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_fn\n",
    ")\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparing Model Results and Training Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "compare_results = pd.DataFrame([model0_results,\n",
    "                                model_1_results,\n",
    "                                model_2_results])\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model: torch.nn.Module,\n",
    "                     data:list,\n",
    "                     device: torch.device = device):\n",
    "    pred_probs = []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for sample in data:\n",
    "            sample = torch.unsqueeze(sample, dim=0).to(device)\n",
    "\n",
    "            pred_logits = model(sample)\n",
    "\n",
    "            pred_prob = torch.softmax(pred_logits.squeeze(), dim=0)\n",
    "\n",
    "            #move pred probs to cpu\n",
    "            pred_probs.append(pred_prob.cpu())\n",
    "\n",
    "    #stack turns list into a tensor\n",
    "    return torch.stack(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "\n",
    "for sample, label in random.sample(list(test_data), k=9):\n",
    "    test_samples.append(sample)\n",
    "    test_labels.append(label)\n",
    "\n",
    "#view first sample sehape\n",
    "test_samples[0].shape, type(test_samples[0]), type(test_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "pred_probs = make_predictions(model=model_2,\n",
    "                              data=test_samples)\n",
    "\n",
    "pred_probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conver probabilities to labels\n",
    "pred_classes = pred_probs.argmax(dim=1)\n",
    "pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "plt.figure(figsize=(9, 9))\n",
    "nrows = 3\n",
    "ncols = 3\n",
    "for i, sample in enumerate(test_samples):\n",
    "  # Create a subplot\n",
    "  plt.subplot(nrows, ncols, i+1)\n",
    "\n",
    "  # Plot the target image\n",
    "  plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
    "\n",
    "  # Find the prediction label (in text form, e.g. \"Sandal\")\n",
    "  pred_label = class_names[pred_classes[i]]\n",
    "\n",
    "  # Get the truth label (in text form, e.g. \"T-shirt\")\n",
    "  truth_label = class_names[test_labels[i]] \n",
    "\n",
    "  # Create the title text of the plot\n",
    "  title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
    "  \n",
    "  # Check for equality and change title colour accordingly\n",
    "  if pred_label == truth_label:\n",
    "      plt.title(title_text, fontsize=10, c=\"g\") # green text if correct\n",
    "  else:\n",
    "      plt.title(title_text, fontsize=10, c=\"r\") # red text if wrong\n",
    "  plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a convolutional neural network \n",
    "class FashionMNISTModelV2(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture copying TinyVGG from: \n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3, # how big is the square that's going over the image?\n",
    "                      stride=1, # default\n",
    "                      padding=1),# options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2) # default stride value is same as kernel_size\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # Where did this in_features shape come from? \n",
    "            # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
    "            nn.Linear(in_features=hidden_units*7*7, \n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.block_1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.block_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_2 = FashionMNISTModelV2(input_shape=1, \n",
    "    hidden_units=10, \n",
    "    output_shape=len(class_names)).to(device)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_2.parameters(), \n",
    "                             lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_model_2 = timer()\n",
    "\n",
    "# Train and test model \n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=train_dataloader, \n",
    "        model=model_2, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "    test_step(data_loader=test_dataloader,\n",
    "        model=model_2,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "train_time_end_model_2 = timer()\n",
    "total_train_time_model_2 = print_train_time(start=train_time_start_model_2,\n",
    "                                           end=train_time_end_model_2,\n",
    "                                           device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model_2 results \n",
    "model_2_results = eval_model(\n",
    "    model=model_2,\n",
    "    data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_fn\n",
    ")\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "for sample, label in random.sample(list(test_data), k=9):\n",
    "    test_samples.append(sample)\n",
    "    test_labels.append(label)\n",
    "\n",
    "# View the first test sample shape and label\n",
    "print(f\"Test sample image shape: {test_samples[0].shape}\\nTest sample label: {test_labels[0]} ({class_names[test_labels[0]]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test samples with model 2\n",
    "pred_probs= make_predictions(model=model_2, \n",
    "                             data=test_samples)\n",
    "\n",
    "# View first two prediction probabilities list\n",
    "pred_probs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test samples with model 2\n",
    "pred_probs= make_predictions(model=model_2, \n",
    "                             data=test_samples)\n",
    "\n",
    "# View first two prediction probabilities list\n",
    "pred_probs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the prediction probabilities into prediction labels by taking the argmax()\n",
    "pred_classes = pred_probs.argmax(dim=1)\n",
    "pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "plt.figure(figsize=(9, 9))\n",
    "nrows = 3\n",
    "ncols = 3\n",
    "for i, sample in enumerate(test_samples):\n",
    "  # Create a subplot\n",
    "  plt.subplot(nrows, ncols, i+1)\n",
    "\n",
    "  # Plot the target image\n",
    "  plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
    "\n",
    "  # Find the prediction label (in text form, e.g. \"Sandal\")\n",
    "  pred_label = class_names[pred_classes[i]]\n",
    "\n",
    "  # Get the truth label (in text form, e.g. \"T-shirt\")\n",
    "  truth_label = class_names[test_labels[i]] \n",
    "\n",
    "  # Create the title text of the plot\n",
    "  title_text = f\"Pred: {pred_label} | Truth: {truth_label}\"\n",
    "  \n",
    "  # Check for equality and change title colour accordingly\n",
    "  if pred_label == truth_label:\n",
    "      plt.title(title_text, fontsize=10, c=\"g\") # green text if correct\n",
    "  else:\n",
    "      plt.title(title_text, fontsize=10, c=\"r\") # red text if wrong\n",
    "  plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
