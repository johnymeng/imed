{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import os\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/jm/VS Code/ML/Time Series Prediction/N_TXT\"\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "fx_data = np.array([], dtype=np.float32)\n",
    "\n",
    "#gets data from file specified by file_path\n",
    "def get_contents(file_path):\n",
    "    global fx_data\n",
    "    skip_lines = 7\n",
    "\n",
    "    with open(file_path,'r') as file:\n",
    "\n",
    "        for skips in range(skip_lines):\n",
    "            next(file)\n",
    "\n",
    "        lines = file.readlines()[:-1]\n",
    "\n",
    "        for line in lines:\n",
    "            data = line.split()[-1]\n",
    "            fx_data = np.append(fx_data, np.float32(data))\n",
    "            #print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go through all files in directory and extract data from txt files\n",
    "for file in os.listdir():\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = f\"{path}/{file}\"\n",
    "        print(f\"Currently working on: {file_path}\")\n",
    "        get_contents(file_path)\n",
    "\n",
    "fx_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create time \"sample\" for dataframe\n",
    "time_data = np.array([], dtype=np.float32)\n",
    "\n",
    "for x in range(len(fx_data)):\n",
    "    time_data = np.append(time_data, np.float32(x))\n",
    "    type(x)\n",
    "\n",
    "time_data, time_data[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create time \"sample\" for dataframe\n",
    "dataset = pd.DataFrame({\"Time\": time_data,\n",
    "                        \"FX Channel\": fx_data})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataset[\"FX Channel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy as dc\n",
    "\n",
    "def lstm_dataframe(df, n_steps):\n",
    "    df = dc(dataset)\n",
    "\n",
    "    #df.set_index(\"FX channel\", inplace=True)\n",
    "\n",
    "    for i in range(1, n_steps+1):\n",
    "        df[f'Time(t-{i})'] = df[\"FX Channel\"].shift(i)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "n_steps = 7\n",
    "shifted_df = lstm_dataframe(dataset, n_steps)\n",
    "shifted_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"FX Channel\"].shape, type(dataset[\"FX Channel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "#split into train, test and validation, convert PD series to numpy first before train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset[\"Time\"].to_numpy(), dataset[\"FX Channel\"].to_numpy(), test_size = 0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "X_train.size, X_test.size, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape X_train and y_train so that we can use scaler from sklearn\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "X_test.shape, X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#scale and normalize data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "scaler.fit_transform(X_train)\n",
    "scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data from numpy to tensors\n",
    "X_train = torch.from_numpy(X_train).type(torch.float32)\n",
    "X_test = torch.from_numpy(X_test).type(torch.float32)\n",
    "y_train = torch.from_numpy(y_train).type(torch.float32)\n",
    "y_test = torch.from_numpy(y_test).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train), X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data.shape, fx_data.shape, fx_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send data to device\n",
    "X_train = X_train.to(device).type(torch.float32) \n",
    "X_test = X_test.to(device).type(torch.float32) \n",
    "y_test = y_test.to(device).type(torch.float32) \n",
    "y_train = y_train.to(device).type(torch.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to split data loader now? not too sure if this is the best way\n",
    "split_idx = int(0.8 * len(dataset))\n",
    "\n",
    "train_data = dataset[:split_idx]\n",
    "test_data = dataset[split_idx:]\n",
    "\n",
    "train_data.size, test_data.size, train_data[\"FX Channel\"], train_data[\"Time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_data.to(device)\n",
    "# fx_data.to(device)\n",
    "# time_data.shape, time_data[7].size, fx_data[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "\n",
    "split_idx = int(0.8 * len(fx_data))\n",
    "print(f\"{split_idx}\")\n",
    "\n",
    "#convert data to use for dataloader\n",
    "class FX_train_dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x = torch.from_numpy(time_data[:split_idx])\n",
    "        self.y = torch.from_numpy(fx_data[:split_idx])\n",
    "        self.n_samples = split_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "#convert data to use for dataloader\n",
    "class FX_test_dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x = torch.from_numpy(time_data[split_idx:])\n",
    "        self.y = torch.from_numpy(fx_data[split_idx:])\n",
    "        self.n_samples = fx_data.shape[0] - split_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = FX_train_dataset()\n",
    "test_data = FX_test_dataset()\n",
    "\n",
    "len(train_data), train_data[0], train_data[100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(10):\n",
    "    print(f\"{train_data[x]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#setup batch size hyperparameter\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "#turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(dataset=train_data, \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data, \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              shuffle=False)\n",
    "\n",
    "#check out what we've created\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\")\n",
    "print(f\"Length of train_dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of train_dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #checkout whats inside the training dataloader\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set manual seed\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model definition\n",
    "\"\"\"\n",
    "class RNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic RNN block. This represents a single layer of RNN\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int) -> None:\n",
    "        \"\"\"\n",
    "        input_size: Number of features of your input vector\n",
    "        hidden_size: Number of hidden neurons\n",
    "        output_size: Number of features of your output vector\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.batch_size = 16\n",
    "\n",
    "        self.i2h = nn.Linear(input_size, hidden_size, bias=False)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden_state) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Returns softmax(linear_out) and tanh(i2h + i2o)\n",
    "        Inputs\n",
    "        ------\n",
    "        x: Input vector x  with shape (vocab_size, )\n",
    "        hidden_state: Hidden state matrix\n",
    "        Outputs\n",
    "        -------\n",
    "        out: Prediction vector\n",
    "        hidden_state: New hidden state matrix\n",
    "        \"\"\"\n",
    "        x = self.i2h(x)\n",
    "       # print(f\"X rnn shape: {x.shape}\")\n",
    "        hidden_state = self.h2h(hidden_state)\n",
    "        hidden_state = torch.tanh(x + hidden_state)\n",
    "       # print(f\"hidden_Staete shape: {hidden_state.shape}\")\n",
    "        return self.h2o(hidden_state), hidden_state\n",
    "\n",
    "    def init_zero_hidden(self, batch_size=1) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns a hidden state with specified batch size. Defaults to 1\n",
    "        \"\"\"\n",
    "        return torch.zeros(batch_size, self.hidden_size, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size = 1,\n",
    "          hidden_size = 16,\n",
    "          output_size = 1,\n",
    "         ).to(device)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=rnn.parameters(),\n",
    "                             lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model: torch.nn.Module,\n",
    "                dataloader: torch.utils.data.DataLoader,\n",
    "                epochs: int,\n",
    "                optimizer: torch.optim,\n",
    "                loss_fn: torch.optim.Optimizer):\n",
    "    train_loss = {}\n",
    "    model.to(device)\n",
    "\n",
    "    #set to train\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = list()\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for batch, (X, y) in enumerate(train_dataloader):\n",
    "            print(X)\n",
    "\n",
    "            hidden = torch.zeros(1, 1, 16) \n",
    "\n",
    "            #print(f\"X shape: {X.shape}\")\n",
    "\n",
    "            X, y, hidden = X.to(device).reshape(1, 16,1), y.to(device), hidden.to(device)\n",
    "            \n",
    "            #make pred\n",
    "            y_pred, hidden = model(X, hidden)\n",
    "\n",
    "            #calc loss\n",
    "            loss += loss_fn(y_pred, y)\n",
    "\n",
    "            #optim zero grad\n",
    "            model.zero_grad()\n",
    "\n",
    "        #back prop\n",
    "        loss.backward()\n",
    "\n",
    "        #optim step\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss.append(loss.detach().item() / len(train_dataloader))\n",
    "\n",
    "        train_loss[epoch] = torch.tensor(epoch_loss).mean()\n",
    "\n",
    "        print(f\"epoch: {epoch} | loss: {train_loss[epoch]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.type, X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "\n",
    "training_loop(model=rnn,\n",
    "              dataloader=train_dataloader,\n",
    "              epochs = EPOCHS,\n",
    "              optimizer=optimizer,\n",
    "              loss_fn=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (torch.Tensor): Truth labels for predictions.\n",
    "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
    "\n",
    "    Returns:\n",
    "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
    "    \"\"\"\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([])\n",
    "\n",
    "# Move values to device\n",
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    \"\"\"Evaluates a given model on a given dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
    "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
    "        loss_fn (torch.nn.Module): The loss function of model.\n",
    "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
    "        device (str, optional): Target device to compute on. Defaults to device.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Results of model making predictions on data_loader.\n",
    "    \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            global predictions\n",
    "\n",
    "            hidden = model.init_zero_hidden(batch_size=model.batch_size)\n",
    "\n",
    "            # Send data to the target device\n",
    "            X, y, hidden = X.reshape(1, len(X), 1).to(device), y.reshape(1, len(X), 1).to(device), hidden\n",
    "\n",
    "            y_pred = model(X, hidden)\n",
    "            print(f\"y pred shape: {y_pred}\")\n",
    "            predictions = np.append(predictions, y_pred)\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "        # Scale loss and acc\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(model=rnn,\n",
    "           data_loader= test_dataloader,\n",
    "           loss_fn = loss_fn,\n",
    "           accuracy_fn=accuracy_fn,\n",
    "           device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot linear data or training and test and predictions (optional)\n",
    "def plot_predictions(\n",
    "    train_data, train_labels, test_data, test_labels, predictions=None\n",
    "):\n",
    "    \"\"\"\n",
    "  Plots linear training data and test data and compares predictions.\n",
    "  \"\"\"\n",
    "    plt.figure(figsize=(20, 15))\n",
    "\n",
    "    # Plot training data in blue\n",
    "    plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "\n",
    "    # Plot test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "    if predictions is not None:\n",
    "        # Plot the predictions in red (predictions were made on the test data)\n",
    "        plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "\n",
    "    # Show the legend\n",
    "    plt.legend(prop={\"size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(X_train.cpu().numpy(), y_train.cpu().numpy(), X_test.cpu().numpy(), y_test.cpu().numpy(), predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing a different model\n",
    "# number of points\n",
    "num_time_steps = len(fx_data)\n",
    "hidden_size = 8\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "lr = 0.1\n",
    "\n",
    "\n",
    "class RNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN_Model, self).__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            # use batch_first for input with another data shape with b first\n",
    "        )\n",
    "        # compress output to the same dim as y\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden_prev):\n",
    "        out, hidden_prev = self.rnn(x, hidden_prev)\n",
    "        # [1, seq, h] => [seq, h]  (batch=1)\n",
    "        out = out.reshape(-1, hidden_size)  # stack batch and seq\n",
    "\n",
    "        # linear layer so that output is not [seq,h] but [seq, 1]\n",
    "        # so it is comparable with y, for loss calculation\n",
    "        out = self.linear(out)  # [seq, h] => [seq, 1]\n",
    "        out = out.unsqueeze(dim=0)  # => [1, seq, 1]\n",
    "        return out, hidden_prev\n",
    "\n",
    "\n",
    "\n",
    "model = RNN_Model()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "hidden_prev = torch.zeros(1, 1, hidden_size)  # [b, layer, mem_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "training_loop(model=model,\n",
    "              dataloader=train_dataloader,\n",
    "              epochs = EPOCHS,\n",
    "              optimizer=optimizer,\n",
    "              loss_fn=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (torch.Tensor): Truth labels for predictions.\n",
    "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
    "\n",
    "    Returns:\n",
    "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
    "    \"\"\"\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([])\n",
    "\n",
    "# Move values to device\n",
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    \"\"\"Evaluates a given model on a given dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
    "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
    "        loss_fn (torch.nn.Module): The loss function of model.\n",
    "        accuracy_fn: An accuracy function to compare the models predictions to the truth labels.\n",
    "        device (str, optional): Target device to compute on. Defaults to device.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Results of model making predictions on data_loader.\n",
    "    \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            global predictions\n",
    "\n",
    "            hidden = torch.zeros(2, 16) \n",
    "            print(f\"{hidden}\")\n",
    "\n",
    "            print(f\"{X}\")\n",
    "\n",
    "            # Send data to the target device\n",
    "            X, y, hidden = X.reshape(1, len(X), 1).to(device), y.reshape(1, len(X), 1).to(device), hidden\n",
    "\n",
    "            y_pred = model(X, hidden)\n",
    "            print(f\"y pred shape: {y_pred}\")\n",
    "            predictions = np.append(predictions, y_pred)\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y, y_pred=y_pred)\n",
    "\n",
    "        # Scale loss and acc\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "    return {\"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(model=rnn,\n",
    "           data_loader= test_dataloader,\n",
    "           loss_fn = loss_fn,\n",
    "           accuracy_fn=accuracy_fn,\n",
    "           device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_stacked_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_stacked_layers = num_stacked_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_stacked_layers, \n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_stacked_layers, batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "model = LSTM(1, 8, 1)\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    model.train(True)\n",
    "    print(f'Epoch: {epoch + 1}')\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_index, batch in enumerate(train_dataloader):\n",
    "        x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "        \n",
    "        output = model(x_batch)\n",
    "        loss = loss_function(output, y_batch)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_index % 100 == 99:  # print every 100 batches\n",
    "            avg_loss_across_batches = running_loss / 100\n",
    "            print('Batch {0}, Loss: {1:.3f}'.format(batch_index+1,\n",
    "                                                    avg_loss_across_batches))\n",
    "            running_loss = 0.0\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch():\n",
    "    model.train(False)\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(test_dataloader):\n",
    "        x_batch, y_batch = X.to(device), y.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(x_batch)\n",
    "            loss = loss_function(output, y_batch)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    avg_loss_across_batches = running_loss / len(test_dataloader)\n",
    "    \n",
    "    print('Val Loss: {0:.3f}'.format(avg_loss_across_batches))\n",
    "    print('***************************************************')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch()\n",
    "    validate_one_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
