{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import os\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This mounts your Google Drive to the Colab VM.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
    "# # assignment folder, e.g. 'cs231n/assignments/assignment1/'\n",
    "# FOLDERNAME = 'PyTorch Test Project/N_TXT'\n",
    "# assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# # Now that we've mounted your Drive, this ensures that\n",
    "# # the Python interpreter of the Colab VM can load\n",
    "# # python files from within it.\n",
    "# import sys\n",
    "# sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "\n",
    "# # This downloads the CIFAR-10 dataset to your Drive\n",
    "# # if it doesn't already exist.\n",
    "# # %cd /content/drive/My\\ Drive/$FOLDERNAME/cs231n/datasets/\n",
    "# # !bash get_datasets.sh\n",
    "# # %cd /content/drive/My\\ Drive/$FOLDERNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/content/drive/MyDrive/PyTorch Test Project/N_TXT\"\n",
    "\n",
    "# os.chdir(path)\n",
    "\n",
    "# fx_data = np.array([], dtype=np.float32)\n",
    "\n",
    "# #gets data from file specified by file_path\n",
    "# def get_contents(file_path):\n",
    "#     global fx_data\n",
    "#     skip_lines = 7\n",
    "\n",
    "#     with open(file_path,'r') as file:\n",
    "\n",
    "#         for skips in range(skip_lines):\n",
    "#             next(file)\n",
    "\n",
    "#         lines = file.readlines()[:-1]\n",
    "\n",
    "#         for line in lines:\n",
    "#             data = line.split()[-1]\n",
    "#             fx_data = np.append(fx_data, np.float32(data))\n",
    "#             #print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\Admin\\\\.vscode\\\\PyTorch\\\\Time Series Prediction\\\\N_TXT\"\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "fx_data = np.array([], dtype=np.float32)\n",
    "\n",
    "#gets data from file specified by file_path\n",
    "def get_contents(file_path):\n",
    "    global fx_data\n",
    "    skip_lines = 7\n",
    "\n",
    "    with open(file_path,'r') as file:\n",
    "\n",
    "        for skips in range(skip_lines):\n",
    "            next(file)\n",
    "\n",
    "        lines = file.readlines()[:-1]\n",
    "\n",
    "        for line in lines:\n",
    "            data = line.split()[-1]\n",
    "            fx_data = np.append(fx_data, np.float32(data))\n",
    "            #print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go through all files in directory and extract data from txt files\n",
    "for file in os.listdir():\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = f\"{path}/{file}\"\n",
    "        \n",
    "\n",
    "        print(f\"Currently working on: {file_path}\")\n",
    "        get_contents(file_path)\n",
    "\n",
    "fx_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create time \"sample\" for dataframe\n",
    "time_data = np.array([], dtype=np.float32)\n",
    "\n",
    "for x in range(len(fx_data)):\n",
    "    time_data = np.append(time_data, np.float32(x))\n",
    "    type(x)\n",
    "\n",
    "time_data, time_data[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create time \"sample\" for dataframe\n",
    "dataset = pd.DataFrame({\"Time\": time_data,\n",
    "                        \"FX Channel\": fx_data})\n",
    "dataset, dataset.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataset[\"Time\"], dataset[\"FX Channel\"]), type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[\"Time\"]\n",
    "y = dataset[\"FX Channel\"]\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to split data loader now? not too sure if this is the best way\n",
    "split_idx = int(0.8 * len(dataset))\n",
    "\n",
    "temp_X_train = X[:split_idx]\n",
    "temp_X_test = X[split_idx:]\n",
    "\n",
    "temp_y_train = y[:split_idx]\n",
    "temp_y_test = y[split_idx:]\n",
    "\n",
    "temp_X_train.shape, temp_X_test.shape, temp_y_train.shape, temp_y_test.shape, len(X), temp_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, nsteps):\n",
    "    data_list = list()\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        end = i + nsteps\n",
    "        if(end > len(data-1)):\n",
    "            break\n",
    "\n",
    "        extracted_data = data[i:end]\n",
    "\n",
    "        data_list.append(extracted_data)\n",
    "\n",
    "    return np.array(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_y_train), y[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 3\n",
    "X_train = split_data(temp_X_train, nsteps)\n",
    "X_test = split_data(temp_X_test, nsteps)\n",
    "y_train = split_data(temp_y_train, nsteps)\n",
    "y_test = split_data(temp_y_test, nsteps)\n",
    "\n",
    "X_train, type(X_train), len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "y_train = scaler.fit_transform(y_train)\n",
    "y_test = scaler.fit_transform(y_test)\n",
    "\n",
    "X_train.shape, y_train.shape, X_train.max(), X_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.unsqueeze(dim = 2)\n",
    "# X_test = X_test.unsqueeze(dim = 2)\n",
    "\n",
    "# X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self,feature,target):\n",
    "        self.feature = feature\n",
    "        self.target = target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.feature)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        item = self.feature[idx]\n",
    "        label = self.target[idx]\n",
    "        \n",
    "        return item,label\n",
    "\n",
    "train_dataset = TimeSeriesDataset(X_train.reshape(X_train.shape[0],X_train.shape[1],1),y_train)\n",
    "test_dataset = TimeSeriesDataset(X_test.reshape(X_test.shape[0],X_test.shape[1],1),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#setup batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "#turn datasets into iterables (batches)\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              shuffle=True,\n",
    "                              drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              shuffle=False, \n",
    "                              drop_last=True)\n",
    "\n",
    "#check out what we've created\n",
    "print(f\"Dataloaders: {train_loader, test_loader}\")\n",
    "print(f\"Length of train_dataloader: {len(train_loader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of train_dataloader: {len(test_loader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, batch in enumerate(train_loader):\n",
    "    x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "    print(x_batch.shape, y_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set manual seed\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1D, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=32, kernel_size=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32, 50)  # Adjust based on the output size of the last conv layer\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = CNN1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN1D().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "valid_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_data, batch_targets in train_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_data.float().to(device))\n",
    "        loss = criterion(outputs.float(), batch_targets.type(torch.float32).to(device))\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.from_numpy(X_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    test_pred = model(X_test.type(torch.float32).to(device)).to('cpu').numpy()\n",
    "\n",
    "plt.plot(y_test, label='Actual FX')\n",
    "plt.plot(test_pred.squeeze(), label='Test Predicted FX')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('FX Channel')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "for sample, label in (test_dataset):\n",
    "\n",
    "    test_samples.append(torch.from_numpy(sample).float())\n",
    "    test_labels.append(torch.from_numpy(label).float())\n",
    "\n",
    "#view first sample sehape\n",
    "len(test_samples), test_samples[0].shape, type(test_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model: torch.nn.Module,\n",
    "                     data:list,\n",
    "                     device: torch.device = device):\n",
    "    predictions_list = []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for sample in data:\n",
    "            print(type(sample))\n",
    "            sample = sample.to(device)\n",
    "\n",
    "            prediction = model(sample)\n",
    "\n",
    "            #move pred probs to cpu\n",
    "            predictions_list.append(prediction.cpu())\n",
    "\n",
    "    #stack turns list into a tensor\n",
    "    return torch.stack(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "pred_probs = make_predictions(model=model,\n",
    "                              data=test_samples)\n",
    "\n",
    "pred_probs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.rand(1000, 50)\n",
    "targets = np.random.rand(1000, 1)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "data_tensor = torch.tensor(data, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(data_tensor).squeeze().numpy()\n",
    "\n",
    "# Plot predictions vs true labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(targets, label='True Labels')\n",
    "plt.plot(predictions, label='Predictions', alpha=0.7)\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Value')\n",
    "plt.title('True Labels vs Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Train():\n",
    "    \n",
    "    running_loss = .0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for idx, (inputs,labels) in enumerate(train_loader):\n",
    "\n",
    "        inputs = inputs.type((torch.float32)).to(device)\n",
    "        # print(f\"shape: {inputs.shape}\")\n",
    "        labels = labels.type(torch.float32).to(device)\n",
    "        # print(inputs)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(inputs.float())\n",
    "        loss = criterion(preds,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "        \n",
    "    train_loss = running_loss/len(train_loader)\n",
    "    train_losses.append(train_loss.detach().cpu().numpy())\n",
    "    \n",
    "    print(f'train_loss {train_loss}')\n",
    "    \n",
    "def Valid():\n",
    "    running_loss = .0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for idx, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs = inputs.type(torch.float32).to(device)\n",
    "            labels = labels.type(torch.float32).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(inputs.float())\n",
    "            loss = criterion(preds,labels)\n",
    "            running_loss += loss\n",
    "            \n",
    "        valid_loss = running_loss/len(test_loader)\n",
    "        valid_losses.append(valid_loss.detach().cpu().numpy())\n",
    "        print(f'valid_loss {valid_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    print('epochs {}/{}'.format(epoch+1,epochs))\n",
    "    Train()\n",
    "    Valid()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(train_acc, label='Train Acc')\n",
    "# plt.plot(test_acc, label='Test Acc')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_x = split_data(X, nsteps)\n",
    "target_y = split_data(y, nsteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(target_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(target_x.transpose(0, 1))\n",
    "torch.reshape(inputs, (len(target_x), 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inputs), len(target_x), (target_x.shape), inputs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "prediction = []\n",
    "batch_size = 1\n",
    "iterations =  int(inputs.shape[0]/1)\n",
    "print(iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iterations-batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(iterations-batch_size):\n",
    "    preds = model(torch.tensor(inputs[i:i + batch_size].transpose(0, 1)).to(device).float())\n",
    "    # print(preds.squeeze().shape)\n",
    "    # prediction.append(preds.detach().squeeze().cpu().numpy())\n",
    "    prediction.append(preds.cpu().squeeze().detach().numpy())\n",
    "    # break\n",
    "\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2,figsize=(11,4))\n",
    "ax[0].set_title('predicted')\n",
    "ax[0].plot(X,prediction)\n",
    "ax[1].set_title('true')\n",
    "ax[1].plot(target_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.transpose(dim0=1, dim1=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for idx, (inputs, labels) in enumerate(test_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                preds = model(inputs.float())\n",
    "                prediction.append(preds.detach().cpu().numpy())               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(prediction), prediction[1][2], len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(target_y, label='Actual FX')\n",
    "plt.plot(prediction, label='Test Predicted FX')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('FX Channel')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    test_pred = model(X_test.transpose(dim0=0, dim1=-1).to(device)).to('cpu').numpy()\n",
    "\n",
    "plt.plot(y_test, label='Actual FX')\n",
    "plt.plot(test_pred.squeeze(), label='Test Predicted FX')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('FX Channel')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = torch.arange(0, 1, 0.000016)\n",
    "temp = temp.unsqueeze(dim=1)\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    test_pred = model(temp.unsqueeze(dim=1)).to('cpu').numpy()\n",
    "\n",
    "# plt.xlim(0, (10000))\n",
    "# plt.ylim(-0, 1)\n",
    "# plt.autoscale(False)\n",
    "plt.plot(y_test, label='Actual FX')\n",
    "plt.plot(test_pred, label='Test Predicted FX')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('FX Channel')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    test_pred = model(X_test.to(device)).to('cpu').numpy()\n",
    "\n",
    "plt.plot(y_test, label='Actual FX')\n",
    "plt.plot(test_pred, label='Test Predicted FX')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('FX Channel')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0], y_test[5800], y_train[0], y_train[23000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.max(), X_test.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
